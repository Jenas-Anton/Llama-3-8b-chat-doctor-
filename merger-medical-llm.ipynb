{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":200209297,"sourceType":"kernelVersion"},{"sourceId":33551,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":28083,"modelId":39106}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U accelerate\n%pip install -U peft\n%pip install -U trl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-10T04:08:05.196082Z","iopub.execute_input":"2024-10-10T04:08:05.196557Z","iopub.status.idle":"2024-10-10T04:09:37.370988Z","shell.execute_reply.started":"2024-10-10T04:08:05.196509Z","shell.execute_reply":"2024-10-10T04:09:37.369447Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"HuggingFace\")\nlogin(token = hf_token)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T04:09:37.373942Z","iopub.execute_input":"2024-10-10T04:09:37.374479Z","iopub.status.idle":"2024-10-10T04:09:38.081279Z","shell.execute_reply.started":"2024-10-10T04:09:37.374422Z","shell.execute_reply":"2024-10-10T04:09:38.080157Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\nnew_model = \"Jenas-Anton/llama-3-8b-chat-doctor\"\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T04:09:38.082860Z","iopub.execute_input":"2024-10-10T04:09:38.083655Z","iopub.status.idle":"2024-10-10T04:09:38.090852Z","shell.execute_reply.started":"2024-10-10T04:09:38.083606Z","shell.execute_reply":"2024-10-10T04:09:38.089574Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom peft import PeftModel\nimport torch\nfrom trl import setup_chat_format\n# Reload tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(base_model)\n\nbase_model_reload = AutoModelForCausalLM.from_pretrained(\n        base_model,\n        return_dict=True,\n        low_cpu_mem_usage=True,\n        torch_dtype=torch.float16,\n        trust_remote_code=True,\n)\n\nbase_model_reload, tokenizer = setup_chat_format(base_model_reload, tokenizer)\n\n# Merge adapter with base model\nmodel = PeftModel.from_pretrained(base_model_reload, new_model)\n\nmodel = model.merge_and_unload()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T04:09:38.093729Z","iopub.execute_input":"2024-10-10T04:09:38.094653Z","iopub.status.idle":"2024-10-10T04:13:31.390718Z","shell.execute_reply.started":"2024-10-10T04:09:38.094601Z","shell.execute_reply":"2024-10-10T04:13:31.389391Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"112e3a5736ab4be88a3becc8cc5b88db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/705 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"527e34b3af774aa0a7ffd4e29817f975"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ca67350563244b4bfe775c2c889825d"}},"metadata":{}}]},{"cell_type":"code","source":"messages = [{\"role\": \"user\", \"content\": \"Hello doctor, I have bad acne. How do I get rid of it?\"}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.float16,\n    device=0  # Use device 0 for GPU\n)\n\n\noutputs = pipe(prompt, max_new_tokens=120, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\nprint(outputs[0][\"generated_text\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-10T04:28:36.029877Z","iopub.execute_input":"2024-10-10T04:28:36.030767Z","iopub.status.idle":"2024-10-10T04:28:47.470514Z","shell.execute_reply.started":"2024-10-10T04:28:36.030718Z","shell.execute_reply":"2024-10-10T04:28:47.469275Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<|im_start|>user\nHello doctor, I have bad acne. How do I get rid of it?<|im_end|>\n<|im_start|>assistant\nSorry to hear that you're struggling with acne! As a doctor, I'll provide you with some general advice and tips to help you get rid of acne. Please note that it's always best to consult a dermatologist for personalized advice.\n\n**Understand Acne:**\nAcne is a common skin condition caused by a combination of factors, including:\n\n1. **Clogged pores:** Dead skin cells, oil, and bacteria combine to block pores, leading to acne.\n2. **Inflammation:** When pores become clogged, bacteria can multiply, causing inflammation and acne.\n3. **\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"llama-3-8b-chat-doctor\")\ntokenizer.save_pretrained(\"llama-3-8b-chat-doctor\")","metadata":{"execution":{"iopub.status.busy":"2024-10-10T04:28:51.745852Z","iopub.execute_input":"2024-10-10T04:28:51.746310Z","iopub.status.idle":"2024-10-10T04:29:50.475874Z","shell.execute_reply.started":"2024-10-10T04:28:51.746273Z","shell.execute_reply":"2024-10-10T04:29:50.474689Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"('llama-3-8b-chat-doctor/tokenizer_config.json',\n 'llama-3-8b-chat-doctor/special_tokens_map.json',\n 'llama-3-8b-chat-doctor/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"model.push_to_hub(\"llama-3-8b-chat-doctor\", use_temp_dir=False)\ntokenizer.push_to_hub(\"llama-3-8b-chat-doctor\", use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T04:29:50.478007Z","iopub.execute_input":"2024-10-10T04:29:50.478394Z","iopub.status.idle":"2024-10-10T04:34:50.535897Z","shell.execute_reply.started":"2024-10-10T04:29:50.478360Z","shell.execute_reply":"2024-10-10T04:34:50.534762Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b7202c0a34f461c82401dfca30ce470"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67153986f3bf46d0bd91d36101e55d51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d2c2787e2e9455aab3117de70e77eba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e458df296330409b9cfbf4235c219bcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7623674deac043938dc18c6df39d2ee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a89ef29ec65a447383d5bcfd5b19e6a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f5f3bd2af934098bd31f9e79e26459d"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Jenas-Anton/llama-3-8b-chat-doctor/commit/bce53e3bbe6064dca2eb0d5d9291b34df9b9385b', commit_message='Upload tokenizer', commit_description='', oid='bce53e3bbe6064dca2eb0d5d9291b34df9b9385b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Jenas-Anton/llama-3-8b-chat-doctor', endpoint='https://huggingface.co', repo_type='model', repo_id='Jenas-Anton/llama-3-8b-chat-doctor'), pr_revision=None, pr_num=None)"},"metadata":{}}]}]}